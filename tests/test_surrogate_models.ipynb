{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('../txf_design-space/')\n",
    "sys.path.append('../txf_design-space/flexibert')\n",
    "sys.path.append('../protran/boshnas/boshnas/')\n",
    "sys.path.append('../global_search/utils')\n",
    "sys.path.append('../')\n",
    "\n",
    "import re\n",
    "import yaml\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import shlex\n",
    "import shutil\n",
    "import argparse\n",
    "import subprocess\n",
    "import collections\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "from embeddings.utils import graph_util, print_util as pu\n",
    "\n",
    "sys.path.append('../txf_design-space/transformers/src/transformers')\n",
    "import embedding_util\n",
    "\n",
    "from boshnas import BOSHNAS\n",
    "from acq import gosh_acq as acq\n",
    "\n",
    "from transformers import BertModel\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from transformers.models.bert.configuration_bert import BertConfig\n",
    "from transformers.models.bert.modeling_modular_bert import BertModelModular, BertForMaskedLMModular, BertForSequenceClassificationModular\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from six.moves import cPickle as pickle\n",
    "from scipy.interpolate import griddata\n",
    "from sklearn.tree import plot_tree\n",
    "from scipy.optimize import minimize, differential_evolution\n",
    "\n",
    "PREFIX_CHECKPOINT_DIR = \"checkpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL\t\t\t\t\tTYPE\t\tITERATIONS\n",
      "f36d5c40c770e4f787c78b43a2a09d78\tshallow_narrow\t1000000\n",
      "e3ea4dd7dab98b7ca6aa439a22e2c669\tdeep_narrow\t1000000\n",
      "cc085bb5b433b6808e32bd7d1ff49584\tdeep_narrow\t937000\n",
      "bec578218d4f893fdd754d7497af18d5\tdeep_narrow\t414500\n",
      "2a8863139d4ccf931452c5f86c3a5a52\tshallow_narrow\t1000000\n",
      "1d41e1cdd47ac30c570648bcddd22ad1\tshallow_narrow\t1000000\n",
      "49ef529d1cada10c9b92463e129424d4\tdeep_narrow\t907000\n",
      "cbf26e711763f177f534ad38b8c7b8a7\tshallow_narrow\t-\n",
      "dc7733ef95c734eee308504f5e0a384e\tshallow_wide\t298500\n",
      "89ca0068830d26fdebfbc79a501b5f2a\tdeep_wide\t-\n",
      "fb76fc6b9cdde469653ce1d3f163b542\tdeep_wide\t242000\n",
      "fb04cff166ed53cb40500c78626889ea\tdeep_wide\t182500\n",
      "7cf1bfa8946458f7f6d261b11a9166bf\tshallow_wide\t-\n",
      "081cb16979c43ce0b68a45650dc2de84\tshallow_wide\t350500\n",
      "ae87fe8c1bbc496d0cfa8bf9e38c6657\tdeep_wide\t-\n",
      "9f4a1d6d19ccb2b1e070cf64ef5c45fe\tshallow_wide\t474000\n"
     ]
    }
   ],
   "source": [
    "# Get Sobol samples and training status\n",
    "glob_dataset_file = '../global_search/dataset/dataset.json'\n",
    "models_dir = '../models/global_search/'\n",
    "\n",
    "dataset = json.load(open(glob_dataset_file, 'r'))\n",
    "\n",
    "print('MODEL\\t\\t\\t\\t\\tTYPE\\t\\tITERATIONS')\n",
    "for model in dataset.keys():\n",
    "    model_dir = os.path.join(models_dir, model)\n",
    "    \n",
    "    # Finding the latest checkpoint for chosen model\n",
    "    re_checkpoint = re.compile(r\"^\" + PREFIX_CHECKPOINT_DIR + r\"\\-(\\d+)$\")\n",
    "    content = os.listdir(model_dir)\n",
    "    checkpoints = [\n",
    "            path\n",
    "            for path in content\n",
    "            if re_checkpoint.search(path) is not None and os.path.isdir(os.path.join(model_dir, path))]\n",
    "    \n",
    "    # Get latest checkpoint\n",
    "    if len(checkpoints) > 0:\n",
    "        checkpoint_dir = max(checkpoints, key=lambda x: int(re_checkpoint.search(x).groups()[0]))\n",
    "        latest_checkpoint = int(checkpoint_dir.split('-')[1])\n",
    "    else:\n",
    "        latest_checkpoint = '-'\n",
    "        \n",
    "    print(f'{model}\\t{dataset[model][\"model_type\"]}\\t{latest_checkpoint}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "txf_design-space [~/.conda/envs/txf_design-space/]",
   "language": "python",
   "name": "conda_txf_design-space"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
