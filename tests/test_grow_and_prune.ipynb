{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('../../txf_design-space/embeddings/utils')\n",
    "sys.path.append('../../txf_design-space/flexibert')\n",
    "sys.path.append('../grow_and_prune/')\n",
    "import graph_util\n",
    "\n",
    "import re\n",
    "import torch\n",
    "import shlex\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "from roberta_pretraining import pretrain\n",
    "import shutil\n",
    "import json\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset, interleave_datasets, load_from_disk\n",
    "from transformers.models.bert.modeling_modular_bert import BertModelModular, BertForMaskedLMModular\n",
    "from transformers import BertModel\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from transformers.models.bert.configuration_bert import BertConfig\n",
    "\n",
    "import argparse\n",
    "import pretrain_model\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from transformers import (\n",
    "    CONFIG_MAPPING,\n",
    "    MODEL_FOR_MASKED_LM_MAPPING,\n",
    "    AutoConfig,\n",
    "    AutoModelForMaskedLM,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    HfArgumentParser,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hash of BERT-Base based on updated hashing: 8b20da51c159887b310cabce176da7fb\n",
      "Loss value of BERT-Base: 1.322\n",
      "Transfering old model hash: 5c6495ca66b551c9aad1e807ebaf5dad to new hash: 4813d0282fdffa4cd219318c04249a5d\n",
      "Transfering old model hash: a3ba08c7b9a3ae0f36811e726d451fd4 to new hash: f811b9a9f5d93fd00e2c9d8d7017fa02\n",
      "Transfering old model hash: a3cee701f7ca71938f27509848754399 to new hash: b8f4c354531c9499aaab1727c5e3e5e8\n",
      "Transfering old model hash: 4b85a450a24a406041b1ef7d83188168 to new hash: c9d0e9133b10da6af36b6c1643da3db5\n",
      "Transfering old model hash: b9d0a0f62da50a38768cc3b0021b78b3 to new hash: fa8fab36a056ef491e17f7100b8ccbf5\n"
     ]
    }
   ],
   "source": [
    "# Get hash of BERT-Base based on updated graph_util.hash_graph()\n",
    "model_dict_hetero = {'l': 12, 'o': [['sa_sdp_64']*12]*12, 'h': [768]*12, 'f': [[3072]]*12}\n",
    "\n",
    "model_graph = graph_util.model_dict_to_graph(model_dict_hetero)\n",
    "old_model_hash = graph_util.hash_graph(*model_graph)\n",
    "model_hash = graph_util.hash_graph(*model_graph, model_dict=model_dict_hetero)\n",
    "\n",
    "print(f'Hash of BERT-Base based on updated hashing: {model_hash}')\n",
    "\n",
    "log_history = json.load(open(os.path.join('../models', old_model_hash, 'log_history.json')))\n",
    "\n",
    "print(f'Loss value of BERT-Base: {min([state[\"loss\"] for state in log_history[:-1]])}')\n",
    "\n",
    "for model_hash in os.listdir(os.path.join('../models', 'grow_wo_ffnn')):\n",
    "    model_dict = json.load(open(os.path.join('../models/grow_wo_ffnn', model_hash, 'model_dict.json')))\n",
    "    \n",
    "    model_graph = graph_util.model_dict_to_graph(model_dict)\n",
    "    new_model_hash = graph_util.hash_graph(*model_graph, model_dict=model_dict)\n",
    "    \n",
    "    print(f'Transfering old model hash: {model_hash} to new hash: {new_model_hash}')\n",
    "    shutil.copytree(os.path.join('../models/grow_wo_ffnn', model_hash), os.path.join('../models', new_model_hash))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.encoder.layer.0.attention.self.distance_embedding.weight', 'roberta.encoder.layer.1.attention.self.distance_embedding.weight', 'roberta.encoder.layer.2.attention.self.distance_embedding.weight', 'roberta.encoder.layer.3.attention.self.distance_embedding.weight', 'roberta.encoder.layer.4.attention.self.distance_embedding.weight', 'roberta.encoder.layer.5.attention.self.distance_embedding.weight', 'roberta.encoder.layer.6.attention.self.distance_embedding.weight', 'roberta.encoder.layer.7.attention.self.distance_embedding.weight', 'roberta.encoder.layer.8.attention.self.distance_embedding.weight', 'roberta.encoder.layer.9.attention.self.distance_embedding.weight', 'roberta.encoder.layer.10.attention.self.distance_embedding.weight', 'roberta.encoder.layer.11.attention.self.distance_embedding.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hash of BERT-Base: 07aaba14d29455a984e2aef6312a8870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../models/07aaba14d29455a984e2aef6312a8870/tokenizer_config.json',\n",
       " '../models/07aaba14d29455a984e2aef6312a8870/special_tokens_map.json',\n",
       " '../models/07aaba14d29455a984e2aef6312a8870/vocab.json',\n",
       " '../models/07aaba14d29455a984e2aef6312a8870/merges.txt',\n",
       " '../models/07aaba14d29455a984e2aef6312a8870/added_tokens.json')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transfer weights of BERT-Base to heterogeneous counterpart\n",
    "roberta_base = RobertaModel.from_pretrained('roberta-base')\n",
    "\n",
    "model_dict_hetero = {'l': 12, 'o': [['sa_sdp_64']*12]*12, 'h': [768]*12, 'f': [[3072]]*12}\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('../txf_design-space/roberta_tokenizer/')\n",
    "config = BertConfig(vocab_size = tokenizer.vocab_size)\n",
    "\n",
    "config.from_model_dict_hetero(model_dict_hetero)\n",
    "\n",
    "model = BertModelModular(config)\n",
    "\n",
    "model_state_dict = model.state_dict()\n",
    "model_state_dict.update(roberta_base.state_dict())\n",
    "model.load_state_dict(model_state_dict)\n",
    "\n",
    "model_graph = graph_util.model_dict_to_graph(model_dict_hetero)\n",
    "model_hash = graph_util.hash_graph(*model_graph)\n",
    "output_dir = '../models/'+model_hash+'/'\n",
    "\n",
    "print(f'Hash of BERT-Base: {model_hash}')\n",
    "\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hash of BERT-Mini: 40f62e468f3458f8d4a5b49ba1413ce6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../models/bert_mini/40f62e468f3458f8d4a5b49ba1413ce6/tokenizer_config.json',\n",
       " '../models/bert_mini/40f62e468f3458f8d4a5b49ba1413ce6/special_tokens_map.json',\n",
       " '../models/bert_mini/40f62e468f3458f8d4a5b49ba1413ce6/vocab.json',\n",
       " '../models/bert_mini/40f62e468f3458f8d4a5b49ba1413ce6/merges.txt',\n",
       " '../models/bert_mini/40f62e468f3458f8d4a5b49ba1413ce6/added_tokens.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model dict for BERT-Mini like model\n",
    "model_dict = {'l': 4, 'o': ['sa']*4, 'h': [256]*4, 'n': [4]*4, 'f': [[1024]]*4, 'p': ['sdp']*4}\n",
    "model_dict_hetero = {'l': 4, 'o': [['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64']]*4, \n",
    "                     'h': [256]*4, 'f': [[1024]]*4}\n",
    "\n",
    "model_graph = graph_util.model_dict_to_graph(model_dict_hetero)\n",
    "old_model_hash = graph_util.hash_graph(*model_graph)\n",
    "model_hash = graph_util.hash_graph(*model_graph, model_dict=model_dict_hetero)\n",
    "\n",
    "print(f'Hash of BERT-Mini: {model_hash}')\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('../txf_design-space/roberta_tokenizer/')\n",
    "\n",
    "config = BertConfig(vocab_size = tokenizer.vocab_size)\n",
    "\n",
    "config.from_model_dict_hetero(model_dict_hetero)\n",
    "\n",
    "model = BertForMaskedLMModular(config)\n",
    "\n",
    "output_dir = '../models/bert_mini/'+model_hash+'/'\n",
    "\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict_bert_mini = {'l': 4, 'o': [['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64'], \\\n",
    "                                      ['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64'], \\\n",
    "                                      ['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64'], \\\n",
    "                                      ['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64']], \n",
    "                        'h': [256, 256, 256, 256], 'f': [[1024], [1024], [1024], [1024]]}\n",
    "json.dump(model_dict_bert_mini, open(os.path.join(output_dir, 'model_dict.json'), 'w+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transfering embeddings using mode: OD\n",
      "Checking layer 0...\n",
      "\tLoading distace embeddings directly\n",
      "\tTransfering attention head 0: sa_sdp_64\n",
      "\tTransfering attention head 1: sa_sdp_64\n",
      "\tTransfering attention head 2: c_13_64\n",
      "\tTransfering attention head 3: sa_wma_64\n",
      "\tTransfering feed-forward layer 0\n",
      "Checking layer 1...\n",
      "\tLoading distace embeddings directly\n",
      "\tTransfering attention head 0: sa_sdp_64\n",
      "\tTransfering attention head 1: sa_sdp_64\n",
      "\tTransfering attention head 2: c_13_64\n",
      "\tTransfering attention head 3: sa_wma_64\n",
      "\tTransfering feed-forward layer 0\n",
      "Checking layer 2...\n",
      "\tLoading distace embeddings directly\n",
      "\tTransfering attention head 0: sa_sdp_64\n",
      "\tTransfering attention head 1: sa_sdp_64\n",
      "\tTransfering attention head 2: c_13_64\n",
      "\tTransfering attention head 3: sa_wma_64\n",
      "\tTransfering feed-forward layer 0\n",
      "Checking layer 3...\n",
      "\tTransfering distance embeddings using mode: OD\n",
      "\tTransfering attention head 0: sa_sdp_32\n",
      "\tTransfering attention head 1: sa_sdp_32\n",
      "\tTransfering attention head 2: c_5_32\n",
      "\tTransfering attention head 3: sa_wma_32\n",
      "\tTransfering feed-forward layer 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test load_from_source()\n",
    "# model_dict_hetero2 = {'l': 4, 'o': [['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64']]*3 + \\\n",
    "#                                    [['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_wma_64']], \n",
    "#                       'h': [256]*4, 'f': [[1024, 1024]]*4}\n",
    "model_dict_hetero2 = {'l': 4, 'o': [['sa_sdp_64', 'sa_sdp_64', 'c_13_64', 'sa_wma_64']]*3 + \\\n",
    "                                    [['sa_sdp_32', 'sa_sdp_32', 'c_5_32', 'sa_wma_32']], \n",
    "                     'h': [128, 256, 256, 512], 'f': [[2048, 256]]*4}\n",
    "# model_dict_hetero2 = {'l': 4, 'o': [['sa_sdp_32', 'sa_sdp_32', 'c_13_32', 'sa_sdp_32']]*4, \n",
    "#                      'h': [256]*4, 'f': [[1024]]*4}\n",
    "\n",
    "config2 = BertConfig(vocab_size = tokenizer.vocab_size)\n",
    "config2.from_model_dict_hetero(model_dict_hetero2)\n",
    "\n",
    "model2 = BertForMaskedLMModular(config2, transfer_mode='OD')\n",
    "\n",
    "# print(model2)\n",
    "\n",
    "model2.bert.load_model_from_source(model.bert, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 64])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bert.encoder.layer[0].attention.self.conv_kernel_layer0.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 128)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test RP\n",
    "from sklearn import random_projection\n",
    "\n",
    "matrix = torch.rand(1000, 1000)\n",
    "matrix_numpy = matrix.cpu().numpy()\n",
    "\n",
    "rp = random_projection.GaussianRandomProjection(128)\n",
    "matrix_numpy_new = rp.fit_transform(matrix_numpy)\n",
    "\n",
    "matrix_numpy_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test RP with torch\n",
    "import torch.nn as nn\n",
    "from torch.tensor import Tensor\n",
    "\n",
    "model.bert.encoder.layer[0].attention.self.query.weight = \\\n",
    "    nn.parameter.Parameter(\n",
    "        torch.from_numpy(\n",
    "            rp.fit_transform(model.bert.encoder.layer[0].attention.self.query.weight.detach().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), ['input', 'sa_h128_p-sdp', 'sa_h128_p-sdp', 'add_norm', 'f512', 'f512', 'add_norm', 'sa_h128_p-sdp', 'sa_h128_p-sdp', 'add_norm', 'f512', 'f512', 'add_norm', 'output'])\n"
     ]
    }
   ],
   "source": [
    "# Test graph generation from model dict\n",
    "model_dict = {'l': 2, 'o': ['sa']*2, 'h': [128]*2, 'n': [2]*2, 'f': [[512, 512]]*2, 'p': ['sdp']*2}\n",
    "\n",
    "model_graph = graph_util.model_dict_to_graph(model_dict)\n",
    "\n",
    "print(model_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'50ef6167847c070825f29805f4e9cd35'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test hashing for model_dict_hetero\n",
    "model_dict_hetero = {'l': 4, 'o': [['l_dft_64', 'sa_wma_64', 'sa_wma_64', 'c_9_64']]*4, \n",
    "                     'h': [256]*4, 'n': [4]*4, 'f': [[1024]]*4}\n",
    "\n",
    "model_graph = graph_util.model_dict_to_graph(model_dict_hetero)\n",
    "\n",
    "graph_util.hash_graph(*model_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_args(seed, max_steps, per_gpu_batch_size, output_dir, local_rank):\n",
    "    a = \"--seed {} \\\n",
    "    --do_train \\\n",
    "    --max_seq_length 512 \\\n",
    "    --per_gpu_train_batch_size {} \\\n",
    "    --max_steps {} \\\n",
    "    --adam_epsilon 1e-6 \\\n",
    "    --adam_beta2 0.98 \\\n",
    "    --learning_rate 1000e-4 \\\n",
    "    --weight_decay 0.01 \\\n",
    "    --save_total_limit 2 \\\n",
    "    --warmup_steps 10000 \\\n",
    "    --lr_scheduler_type linear \\\n",
    "    --output_dir {} \\\n",
    "    --local_rank {} \\\n",
    "    --gradient_accumulation_steps 4 \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 10 \\\n",
    "        \".format(seed, per_gpu_batch_size, max_steps, output_dir, local_rank)\n",
    "    return shlex.split(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT-Mini's model hash: 7f3d35e33a37f8d6a55d3d3ee339d7ba\n",
      "02/16/2022 17:18:54 - WARNING - roberta_pretraining -   Process rank: -1, device: cpu, n_gpu: 0distributed training: False, 16-bits training: False\n",
      "02/16/2022 17:18:54 - INFO - roberta_pretraining -   Training/evaluation parameters TrainingArguments(output_dir=./models/7f3d35e33a37f8d6a55d3d3ee339d7ba/, overwrite_output_dir=False, do_train=True, do_eval=None, do_predict=False, evaluation_strategy=IntervalStrategy.NO, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, gradient_accumulation_steps=4, eval_accumulation_steps=None, learning_rate=0.1, weight_decay=0.01, adam_beta1=0.9, adam_beta2=0.98, adam_epsilon=1e-06, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=100, lr_scheduler_type=SchedulerType.LINEAR, warmup_ratio=0.0, warmup_steps=10000, logging_dir=runs/Feb16_17-18-54_della-r2c3n1, logging_strategy=IntervalStrategy.STEPS, logging_first_step=False, logging_steps=10, save_strategy=IntervalStrategy.STEPS, save_steps=10, save_total_limit=2, no_cuda=False, seed=0, fp16=False, fp16_opt_level=O1, fp16_backend=auto, fp16_full_eval=False, local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=10, dataloader_num_workers=0, past_index=-1, run_name=./models/7f3d35e33a37f8d6a55d3d3ee339d7ba/, disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, length_column_name=length, report_to=[], ddp_find_unused_parameters=None, dataloader_pin_memory=True, skip_memory_metrics=False, _n_gpu=0, mp_parameters=)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|tokenization_utils_base.py:1647] 2022-02-16 17:18:54,444 >> Didn't find file /scratch/gpfs/stuli/txf_design-space/roberta_tokenizer/added_tokens.json. We won't load it.\n",
      "[INFO|tokenization_utils_base.py:1647] 2022-02-16 17:18:54,446 >> Didn't find file /scratch/gpfs/stuli/txf_design-space/roberta_tokenizer/tokenizer.json. We won't load it.\n",
      "[INFO|tokenization_utils_base.py:1711] 2022-02-16 17:18:54,447 >> loading file /scratch/gpfs/stuli/txf_design-space/roberta_tokenizer/vocab.json\n",
      "[INFO|tokenization_utils_base.py:1711] 2022-02-16 17:18:54,448 >> loading file /scratch/gpfs/stuli/txf_design-space/roberta_tokenizer/merges.txt\n",
      "[INFO|tokenization_utils_base.py:1711] 2022-02-16 17:18:54,449 >> loading file None\n",
      "[INFO|tokenization_utils_base.py:1711] 2022-02-16 17:18:54,451 >> loading file /scratch/gpfs/stuli/txf_design-space/roberta_tokenizer/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:1711] 2022-02-16 17:18:54,452 >> loading file /scratch/gpfs/stuli/txf_design-space/roberta_tokenizer/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:1711] 2022-02-16 17:18:54,453 >> loading file None\n",
      "[INFO|trainer.py:375] 2022-02-16 17:19:00,998 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:488] 2022-02-16 17:19:00,999 >> The following columns in the training set  don't have a corresponding argument in `BertForMaskedLMModular.forward` and have been ignored: special_tokens_mask.\n",
      "[WARNING|training_args.py:633] 2022-02-16 17:19:01,000 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
      "[WARNING|training_args.py:633] 2022-02-16 17:19:01,002 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
      "[INFO|trainer.py:1011] 2022-02-16 17:19:01,002 >> ***** Running training *****\n",
      "[INFO|trainer.py:1012] 2022-02-16 17:19:01,002 >>   Num examples = 3149357\n",
      "[INFO|trainer.py:1013] 2022-02-16 17:19:01,003 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1014] 2022-02-16 17:19:01,003 >>   Instantaneous batch size per device = 8\n",
      "[INFO|trainer.py:1015] 2022-02-16 17:19:01,003 >>   Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "[INFO|trainer.py:1016] 2022-02-16 17:19:01,003 >>   Gradient Accumulation steps = 4\n",
      "[INFO|trainer.py:1017] 2022-02-16 17:19:01,004 >>   Total optimization steps = 100\n"
     ]
    }
   ],
   "source": [
    "# Test loss from manual GP\n",
    "model_dict_bert_mini = {'l': 4, 'o': [['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64']]*4, \n",
    "                     'h': [256]*4, 'f': [[1024]]*4}\n",
    "model_graph_bert_mini = graph_util.model_dict_to_graph(model_dict_bert_mini)\n",
    "model_hash_bert_mini = graph_util.hash_graph(*model_graph_bert_mini)\n",
    "\n",
    "print(f'BERT-Mini\\'s model hash: {model_hash_bert_mini}')\n",
    "\n",
    "output_dir_bert_mini = f'./models/{model_hash_bert_mini}/'\n",
    "\n",
    "args_train = get_training_args(0, 100, 32, output_dir_bert_mini, -1)\n",
    "\n",
    "if os.path.exists(output_dir_bert_mini):\n",
    "    shutil.rmtree(output_dir_bert_mini)\n",
    "\n",
    "metrics, log_history_bert_mini = pretrain(args_train, model_dict_bert_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loss after load_from_source of the same model\n",
    "model_dict_new = model_dict_bert_mini\n",
    "model_graph_new = graph_util.model_dict_to_graph(model_dict_new)\n",
    "model_hash_new = graph_util.hash_graph(*model_graph_new) + '_new'\n",
    "\n",
    "print(f'New model\\'s hash: {model_hash_new}')\n",
    "\n",
    "output_dir_new = f'./models/{model_hash_new}'\n",
    "\n",
    "chosen_neighbor_model = BertModelModular.from_pretrained(output_dir_bert_mini)\n",
    "\n",
    "# Finding the latest checkpoint for BERT-Mini\n",
    "PREFIX_CHECKPOINT_DIR = \"checkpoint\"\n",
    "_re_checkpoint = re.compile(r\"^\" + PREFIX_CHECKPOINT_DIR + r\"\\-(\\d+)$\")\n",
    "\n",
    "content = os.listdir(output_dir_bert_mini)\n",
    "checkpoints = [\n",
    "        path\n",
    "        for path in content\n",
    "        if _re_checkpoint.search(path) is not None and os.path.isdir(os.path.join(output_dir_bert_mini, path))\n",
    "    ]\n",
    "checkpoint_dir = max(checkpoints, key=lambda x: int(_re_checkpoint.search(x).groups()[0]))\n",
    "# print(checkpoint_dir)\n",
    "                \n",
    "tokenizer = RobertaTokenizer.from_pretrained('../txf_design-space/roberta_tokenizer/')\n",
    "config_new = BertConfig(vocab_size = tokenizer.vocab_size)\n",
    "config_new.from_model_dict_hetero(model_dict_new)\n",
    "    \n",
    "model_new = BertModelModular(config_new)\n",
    "model_new.load_model_from_source(chosen_neighbor_model)\n",
    "\n",
    "# Setting up checkpoint for new model\n",
    "if os.path.exists(output_dir_new):\n",
    "    shutil.rmtree(output_dir_new)\n",
    "shutil.copytree(os.path.join(output_dir_bert_mini, checkpoint_dir), os.path.join(output_dir_new, checkpoint_dir))\n",
    "os.remove(os.path.join(output_dir_new, checkpoint_dir, 'optimizer.pt'))\n",
    "# os.remove(os.path.join(output_dir_new, checkpoint_dir, 'scheduler.pt'))\n",
    "model_new.save_pretrained(os.path.join(output_dir_new, checkpoint_dir))\n",
    "\n",
    "args_train = get_training_args(0, 200, 32, output_dir_new, -1)\n",
    "\n",
    "metrics, log_history_bert_mini_new = pretrain(args_train, model_dict_bert_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loss from manual GP\n",
    "model_dict_new = {'l': 4, 'o': [['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64']]*3 + \\\n",
    "                  [['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_wma_64']], \n",
    "        'h': [256]*4, 'f': [[1024]]*4}\n",
    "model_graph_new = graph_util.model_dict_to_graph(model_dict_new)\n",
    "model_hash_new = graph_util.hash_graph(*model_graph_new)\n",
    "\n",
    "print(f'New model\\'s hash: {model_hash_new}')\n",
    "\n",
    "output_dir_new = f'./models/{model_hash_new}'\n",
    "\n",
    "chosen_neighbor_model = BertModelModular.from_pretrained(output_dir_bert_mini)\n",
    "\n",
    "# Finding the latest checkpoint for BERT-Mini\n",
    "PREFIX_CHECKPOINT_DIR = \"checkpoint\"\n",
    "_re_checkpoint = re.compile(r\"^\" + PREFIX_CHECKPOINT_DIR + r\"\\-(\\d+)$\")\n",
    "\n",
    "content = os.listdir(output_dir_bert_mini)\n",
    "checkpoints = [\n",
    "        path\n",
    "        for path in content\n",
    "        if _re_checkpoint.search(path) is not None and os.path.isdir(os.path.join(output_dir_bert_mini, path))\n",
    "    ]\n",
    "checkpoint_dir = max(checkpoints, key=lambda x: int(_re_checkpoint.search(x).groups()[0]))\n",
    "# print(checkpoint_dir)\n",
    "                \n",
    "tokenizer = RobertaTokenizer.from_pretrained('../txf_design-space/roberta_tokenizer/')\n",
    "config_new = BertConfig(vocab_size = tokenizer.vocab_size)\n",
    "config_new.from_model_dict_hetero(model_dict_new)\n",
    "    \n",
    "model_new = BertModelModular(config_new)\n",
    "model_new.load_model_from_source(chosen_neighbor_model)\n",
    "\n",
    "# Setting up checkpoint for new model\n",
    "if os.path.exists(output_dir_new):\n",
    "    shutil.rmtree(output_dir_new)\n",
    "shutil.copytree(os.path.join(output_dir_bert_mini, checkpoint_dir), os.path.join(output_dir_new, checkpoint_dir))\n",
    "os.remove(os.path.join(output_dir_new, checkpoint_dir, 'optimizer.pt'))\n",
    "# os.remove(os.path.join(output_dir_new, checkpoint_dir, 'scheduler.pt'))\n",
    "model_new.save_pretrained(os.path.join(output_dir_new, checkpoint_dir))\n",
    "\n",
    "args_train = get_training_args(0, 200, 32, output_dir_new, -1)\n",
    "\n",
    "metrics, log_history_model_new = pretrain(args_train, model_dict_bert_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss of grown model vs. original model with loss saturated\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot([state['step'] for state in log_history_bert_mini[:-1]], \n",
    "        [state['loss'] for state in log_history_bert_mini[:-1]], label='BERT-Mini')\n",
    "plt.plot([state['step'] for state in log_history_model_new[10:-1]], \n",
    "        [state['loss'] for state in log_history_model_new[10:-1]], label='Grown Model')\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Training Steps')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test automatic block-level growth\n",
    "model_dict = {'l': 4, 'o': [['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64'], \\\n",
    "                           ['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64'], \\\n",
    "                           ['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64'], \\\n",
    "                           ['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64']], \n",
    "                     'h': [256]*4, 'f': [[1024]]*4}\n",
    "\n",
    "ops = ['sa_sdp', 'sa_wma', 'l_dft', 'l_dct', 'c_5', 'c_9', 'c_13']\n",
    "\n",
    "num_samples = 10\n",
    "for sample_idx in range(num_samples):\n",
    "    layer = random.randint(0, model_dict['l']-1)\n",
    "    op = random.sample(ops, 1)[0]\n",
    "    \n",
    "    model_dict_new = deepcopy(model_dict)\n",
    "    \n",
    "    layer_hidden_dim = model_dict_new['o'][layer][0].split('_')[2]\n",
    "    model_dict_new['o'][layer].append(op + '_' +  layer_hidden_dim)\n",
    "    \n",
    "    print(model_dict_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test block-level pruning\n",
    "model_dict = {'l': 4, 'o': [['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_wma_64'], \\\n",
    "                           ['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'c_5_64'], \\\n",
    "                           ['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64'], \\\n",
    "                           ['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64']], \n",
    "                     'h': [256]*4, 'f': [[1024, 1024, 1024]]*4}\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('../txf_design-space/roberta_tokenizer/')\n",
    "\n",
    "config = BertConfig(vocab_size = tokenizer.vocab_size)\n",
    "config.from_model_dict_hetero(model_dict)\n",
    "\n",
    "model = BertForMaskedLMModular(config)\n",
    "\n",
    "for i in range(model_dict['l']):\n",
    "    attention_head_size = int(model_dict['o'][i][0].split('_')[2])\n",
    "    attention_layer = model.bert.encoder.layer[i].attention.self\n",
    "    wma_count, conv_count = 0, 0\n",
    "    for j in range(len(model_dict['o'][i])):\n",
    "        query_mean = torch.mean(torch.square(\n",
    "            attention_layer.query.weight[j*attention_head_size:(j+1)*attention_head_size])).item()\n",
    "        key_mean = torch.mean(torch.square(\n",
    "            attention_layer.key.weight[j*attention_head_size:(j+1)*attention_head_size])).item()\n",
    "        value_mean = torch.mean(torch.square(\n",
    "            attention_layer.value.weight[j*attention_head_size:(j+1)*attention_head_size])).item()\n",
    "        weights = [query_mean, key_mean, value_mean]\n",
    "        if model_dict['o'][i][j].split('_')[1] == 'wma':\n",
    "            wma_mean = torch.mean(torch.square(\n",
    "                getattr(attention_layer, f'W{wma_count}'))).item()\n",
    "            weights.append(wma_mean)\n",
    "            wma_count += 1\n",
    "        elif model_dict['o'][i][j].split('_')[1].isnumeric():\n",
    "            key_conv_attn_layer_mean = np.mean([torch.mean(torch.square(\n",
    "                getattr(attention_layer, f'key_conv_attn_layer{conv_count}').depthwise.weight)).item(),\n",
    "                                                torch.mean(torch.square(\n",
    "                getattr(attention_layer, f'key_conv_attn_layer{conv_count}').pointwise.weight)).item()])\n",
    "            conv_kernel_layer_mean = torch.mean(torch.square(\n",
    "                getattr(attention_layer, f'conv_kernel_layer{conv_count}').weight)).item()\n",
    "            conv_out_layer_mean = torch.mean(torch.square(\n",
    "                getattr(attention_layer, f'conv_out_layer{conv_count}').weight)).item()\n",
    "            conv_mean = np.mean([key_conv_attn_layer_mean, conv_kernel_layer_mean, conv_out_layer_mean])\n",
    "            weights.append(conv_mean)\n",
    "            conv_count += 1\n",
    "        print(f'Layer {i}, Attention head {j}, mean: {np.mean(weights): 0.3e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Trainer\n",
    "tokenized_datasets = load_from_disk(f'../../txf_design-space/tokenized_pretraining_dataset')\n",
    "\n",
    "train_dataset = tokenized_datasets[\"train\"]\n",
    "train_dataset = train_dataset.select(range(100))\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm_probability=0.1,\n",
    "    pad_to_multiple_of=None,\n",
    ")\n",
    "\n",
    "training_args = get_training_args(0, 1, 1, './models/test_model/', -1)\n",
    "\n",
    "MODEL_CONFIG_CLASSES = list(MODEL_FOR_MASKED_LM_MAPPING.keys())\n",
    "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)\n",
    "\n",
    "@dataclass\n",
    "class ModelArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune, or train from scratch.\n",
    "    \"\"\"\n",
    "\n",
    "    model_name_or_path: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"The model checkpoint for weights initialization.\"\n",
    "            \"Don't set if you want to train a model from scratch.\"\n",
    "        },\n",
    "    )\n",
    "    model_type: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"If training from scratch, pass a model type from the list: \" + \", \".join(MODEL_TYPES)},\n",
    "    )\n",
    "    config_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n",
    "    )\n",
    "    tokenizer_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n",
    "    )\n",
    "    cache_dir: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"Where do you want to store the pretrained models downloaded from huggingface.co\"},\n",
    "    )\n",
    "    use_fast_tokenizer: bool = field(\n",
    "        default=True,\n",
    "        metadata={\"help\": \"Whether to use one of the fast tokenizer (backed by the tokenizers library) or not.\"},\n",
    "    )\n",
    "    model_revision: str = field(\n",
    "        default=\"main\",\n",
    "        metadata={\"help\": \"The specific model version to use (can be a branch name, tag name or commit id).\"},\n",
    "    )\n",
    "    use_auth_token: bool = field(\n",
    "        default=False,\n",
    "        metadata={\n",
    "            \"help\": \"Will use the token generated when running `transformers-cli login` (necessary to use this script \"\n",
    "            \"with private models).\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataTrainingArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to what data we are going to input our model for training and eval.\n",
    "    \"\"\"\n",
    "\n",
    "    dataset_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"The name of the dataset to use (via the datasets library).\"}\n",
    "    )\n",
    "    dataset_config_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"The configuration name of the dataset to use (via the datasets library).\"}\n",
    "    )\n",
    "    train_file: Optional[str] = field(default=None, metadata={\"help\": \"The input training data file (a text file).\"})\n",
    "    validation_file: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"An optional input evaluation data file to evaluate the perplexity on (a text file).\"},\n",
    "    )\n",
    "    overwrite_cache: bool = field(\n",
    "        default=False, metadata={\"help\": \"Overwrite the cached training and evaluation sets\"}\n",
    "    )\n",
    "    validation_split_percentage: Optional[int] = field(\n",
    "        default=5,\n",
    "        metadata={\n",
    "            \"help\": \"The percentage of the train set used as validation set in case there's no validation split\"\n",
    "        },\n",
    "    )\n",
    "    max_seq_length: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"The maximum total input sequence length after tokenization. Sequences longer \"\n",
    "            \"than this will be truncated.\"\n",
    "        },\n",
    "    )\n",
    "    preprocessing_num_workers: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"The number of processes to use for the preprocessing.\"},\n",
    "    )\n",
    "    mlm_probability: float = field(\n",
    "        default=0.15, metadata={\"help\": \"Ratio of tokens to mask for masked language modeling loss\"}\n",
    "    )\n",
    "    line_by_line: bool = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"Whether distinct lines of text in the dataset are to be handled as distinct sequences.\"},\n",
    "    )\n",
    "    pad_to_max_length: bool = field(\n",
    "        default=False,\n",
    "        metadata={\n",
    "            \"help\": \"Whether to pad all samples to `max_seq_length`. \"\n",
    "            \"If False, will pad the samples dynamically when batching to the maximum length in the batch.\"\n",
    "        },\n",
    "    )\n",
    "    max_train_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"For debugging purposes or quicker training, truncate the number of training examples to this \"\n",
    "            \"value if set.\"\n",
    "        },\n",
    "    )\n",
    "    max_val_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"For debugging purposes or quicker training, truncate the number of validation examples to this \"\n",
    "            \"value if set.\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "    '''\n",
    "    def __post_init__(self):\n",
    "        if self.dataset_name is None and self.train_file is None and self.validation_file is None:\n",
    "            raise ValueError(\"Need either a dataset name or a training/validation file.\")\n",
    "        else:\n",
    "            if self.train_file is not None:\n",
    "                extension = self.train_file.split(\".\")[-1]\n",
    "                assert extension in [\"csv\", \"json\", \"txt\"], \"`train_file` should be a csv, a json or a txt file.\"\n",
    "            if self.validation_file is not None:\n",
    "                extension = self.validation_file.split(\".\")[-1]\n",
    "                assert extension in [\"csv\", \"json\", \"txt\"], \"`validation_file` should be a csv, a json or a txt file.\"\n",
    "    '''\n",
    "\n",
    "parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TrainingArguments))\n",
    "_, _, training_args = parser.parse_args_into_dataclasses(args_train)\n",
    "set_seed(training_args.seed)\n",
    "\n",
    "# Initialize our Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test FFNN gradients\n",
    "if os.path.exists('./models/test_model/'):\n",
    "    shutil.rmtree('./models/test_model/')\n",
    "    \n",
    "args_train = get_training_args(0, 1, 1, './models/test_model/', -1)\n",
    "\n",
    "parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TrainingArguments))\n",
    "_, _, args_train = parser.parse_args_into_dataclasses(args_train)\n",
    "set_seed(args_train.seed)\n",
    "\n",
    "# Initialize our Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args_train,\n",
    "    train_dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "train_dataloader = trainer.get_train_dataloader()\n",
    "for step, inputs in enumerate(train_dataloader):\n",
    "    model.train()\n",
    "    inputs = trainer._prepare_inputs(inputs)\n",
    "    loss = trainer.compute_loss(model, inputs)\n",
    "    loss.backward()\n",
    "    break\n",
    "    \n",
    "weight_grad = model.bert.encoder.layer[0].intermediate.sequential[0].weight.grad.cpu().numpy()\n",
    "print(f'weight_grad.shape: {weight_grad.shape}')\n",
    "weight_grad = np.abs(weight_grad)\n",
    "\n",
    "print(f'argmax(weight_grad): {np.unravel_index(np.argmax(weight_grad), weight_grad.shape)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test weight gradients for neuron-level growth in FFNN\n",
    "\n",
    "models_dir = '../models'\n",
    "model_hash = '07aaba14d29455a984e2aef6312a8870'\n",
    "\n",
    "if os.path.exists(os.path.join(models_dir, 'test_models', model_hash)):\n",
    "    shutil.rmtree(os.path.join(models_dir, 'test_models', model_hash))\n",
    "shutil.copytree(os.path.join(models_dir, model_hash), os.path.join(models_dir, 'test_models', model_hash))\n",
    "\n",
    "# Get model dictionary\n",
    "model_dict = json.load(open(os.path.join(models_dir, 'test_models', model_hash, 'model_dict.json'), 'r'))\n",
    "\n",
    "# Get training arguments for pre-training\n",
    "def _get_training_args(seed, max_steps, per_gpu_batch_size, output_dir, local_rank):\n",
    "    a = \"--seed {} \\\n",
    "    --do_train \\\n",
    "    --max_seq_length 512 \\\n",
    "    --per_gpu_train_batch_size {} \\\n",
    "    --gradient_accumulation_steps 4 \\\n",
    "    --max_steps {} \\\n",
    "    --adam_epsilon 1e-6 \\\n",
    "    --adam_beta2 0.98 \\\n",
    "    --learning_rate 1000e-4 \\\n",
    "    --weight_decay 0.01 \\\n",
    "    --save_total_limit 2 \\\n",
    "    --warmup_steps 10000 \\\n",
    "    --lr_scheduler_type linear \\\n",
    "    --output_dir {} \\\n",
    "    --local_rank {} \\\n",
    "    --gradient_accumulation_steps 4 \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 10 \\\n",
    "        \".format(seed, per_gpu_batch_size, max_steps, output_dir, local_rank)\n",
    "    return shlex.split(a)\n",
    "\n",
    "# Instantiate Trainer\n",
    "tokenized_datasets = load_from_disk(f'../../txf_design-space/tokenized_pretraining_dataset')\n",
    "tokenizer = RobertaTokenizer.from_pretrained('../../txf_design-space/roberta_tokenizer/')\n",
    "\n",
    "train_dataset = tokenized_datasets[\"train\"]\n",
    "train_dataset = train_dataset.select(range(100))\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm_probability=0.1,\n",
    "    pad_to_multiple_of=None,\n",
    ")\n",
    "\n",
    "# Get arguments for pre-training\n",
    "training_args = _get_training_args(0, 1, 16, os.path.join(models_dir, 'test_models', model_hash), -1)\n",
    "\n",
    "MODEL_CONFIG_CLASSES = list(MODEL_FOR_MASKED_LM_MAPPING.keys())\n",
    "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)\n",
    "\n",
    "@dataclass\n",
    "class ModelArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune, or train from scratch.\n",
    "    \"\"\"\n",
    "\n",
    "    model_name_or_path: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"The model checkpoint for weights initialization.\"\n",
    "            \"Don't set if you want to train a model from scratch.\"\n",
    "        },\n",
    "    )\n",
    "    model_type: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"If training from scratch, pass a model type from the list: \" + \", \".join(MODEL_TYPES)},\n",
    "    )\n",
    "    config_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n",
    "    )\n",
    "    tokenizer_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n",
    "    )\n",
    "    cache_dir: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"Where do you want to store the pretrained models downloaded from huggingface.co\"},\n",
    "    )\n",
    "    use_fast_tokenizer: bool = field(\n",
    "        default=True,\n",
    "        metadata={\"help\": \"Whether to use one of the fast tokenizer (backed by the tokenizers library) or not.\"},\n",
    "    )\n",
    "    model_revision: str = field(\n",
    "        default=\"main\",\n",
    "        metadata={\"help\": \"The specific model version to use (can be a branch name, tag name or commit id).\"},\n",
    "    )\n",
    "    use_auth_token: bool = field(\n",
    "        default=False,\n",
    "        metadata={\n",
    "            \"help\": \"Will use the token generated when running `transformers-cli login` (necessary to use this script \"\n",
    "            \"with private models).\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataTrainingArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to what data we are going to input our model for training and eval.\n",
    "    \"\"\"\n",
    "\n",
    "    dataset_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"The name of the dataset to use (via the datasets library).\"}\n",
    "    )\n",
    "    dataset_config_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"The configuration name of the dataset to use (via the datasets library).\"}\n",
    "    )\n",
    "    train_file: Optional[str] = field(default=None, metadata={\"help\": \"The input training data file (a text file).\"})\n",
    "    validation_file: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"An optional input evaluation data file to evaluate the perplexity on (a text file).\"},\n",
    "    )\n",
    "    overwrite_cache: bool = field(\n",
    "        default=False, metadata={\"help\": \"Overwrite the cached training and evaluation sets\"}\n",
    "    )\n",
    "    validation_split_percentage: Optional[int] = field(\n",
    "        default=5,\n",
    "        metadata={\n",
    "            \"help\": \"The percentage of the train set used as validation set in case there's no validation split\"\n",
    "        },\n",
    "    )\n",
    "    max_seq_length: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"The maximum total input sequence length after tokenization. Sequences longer \"\n",
    "            \"than this will be truncated.\"\n",
    "        },\n",
    "    )\n",
    "    preprocessing_num_workers: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"The number of processes to use for the preprocessing.\"},\n",
    "    )\n",
    "    mlm_probability: float = field(\n",
    "        default=0.15, metadata={\"help\": \"Ratio of tokens to mask for masked language modeling loss\"}\n",
    "    )\n",
    "    line_by_line: bool = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"Whether distinct lines of text in the dataset are to be handled as distinct sequences.\"},\n",
    "    )\n",
    "    pad_to_max_length: bool = field(\n",
    "        default=False,\n",
    "        metadata={\n",
    "            \"help\": \"Whether to pad all samples to `max_seq_length`. \"\n",
    "            \"If False, will pad the samples dynamically when batching to the maximum length in the batch.\"\n",
    "        },\n",
    "    )\n",
    "    max_train_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"For debugging purposes or quicker training, truncate the number of training examples to this \"\n",
    "            \"value if set.\"\n",
    "        },\n",
    "    )\n",
    "    max_val_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"For debugging purposes or quicker training, truncate the number of validation examples to this \"\n",
    "            \"value if set.\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "local_parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TrainingArguments))\n",
    "_, _, training_args = local_parser.parse_args_into_dataclasses(training_args)\n",
    "set_seed(training_args.seed)\n",
    "\n",
    "# Instantiate model\n",
    "model = BertForMaskedLMModular.from_pretrained(os.path.join(models_dir, 'test_models', model_hash, 'checkpoint-72000'))\n",
    "\n",
    "# Initialize our Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "train_dataloader = trainer.get_train_dataloader()\n",
    "for step, inputs in enumerate(train_dataloader):\n",
    "    model.train()\n",
    "    inputs = trainer._prepare_inputs(inputs)\n",
    "    loss = trainer.compute_loss(model, inputs)\n",
    "    loss.backward()\n",
    "    break\n",
    "\n",
    "weight_grads = []\n",
    "\n",
    "for i in range(model_dict['l']):\n",
    "    for j in range(len(model_dict['f'][i])):\n",
    "        weight_grad = model.bert.encoder.layer[i].intermediate.sequential[j].weight.grad.cpu().numpy()\n",
    "        weight_grad = np.abs(weight_grad)\n",
    "\n",
    "        weight_grads.append({'layer': i, 'feed_forward_layer': j, 'weight_grad': np.mean(weight_grad)})\n",
    "  \n",
    "print(weight_grads)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test weight values for neuron-level pruning in FFNN\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "with torch.no_grad():\n",
    "    plt.plot(np.sort(np.mean(\n",
    "        np.abs(model.bert.encoder.layer[0].intermediate.sequential[0].weight.cpu().numpy()), axis=1)))\n",
    "plt.show()\n",
    "\n",
    "for i in range(model_dict['l']):\n",
    "    per_improvs = []\n",
    "    for j in range(len(model_dict['f'][i])):\n",
    "        with torch.no_grad():\n",
    "            weights_sorted = np.sort(np.mean(\n",
    "                np.abs(model.bert.encoder.layer[i].intermediate.sequential[0].weight.cpu().numpy()), axis=1))\n",
    "\n",
    "        weights_mean = np.mean(weights_sorted)\n",
    "        weights_pruned = np.mean(weights_sorted[16:])\n",
    "        \n",
    "        per_improv = (weights_pruned - weights_mean) / weights_mean\n",
    "        per_improvs.append(per_improv)\n",
    "\n",
    "    print(np.mean(per_improvs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'l': 12, 'o': [['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_wma_64'], ['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64'], ['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64'], ['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64'], ['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64'], ['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64'], ['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64'], ['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64'], ['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64'], ['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64'], ['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64'], ['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64']], 'h': [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], 'f': [[3072], [3072], [3072], [3072], [3072], [3072], [3072], [3072], [3072], [3072], [3072], [3072]]}\n",
      "Loading embeddings directly\n",
      "Checking layer 0...\n",
      "\tLoading distace embeddings directly\n",
      "\tTransfering attention head 0: sa_sdp_64\n",
      "\tTransfering attention head 1: sa_sdp_64\n",
      "\tTransfering attention head 2: sa_sdp_64\n",
      "\tTransfering attention head 3: sa_sdp_64\n",
      "\tTransfering attention head 4: sa_sdp_64\n",
      "\tTransfering attention head 5: sa_sdp_64\n",
      "\tTransfering attention head 6: sa_sdp_64\n",
      "\tTransfering attention head 7: sa_sdp_64\n",
      "\tTransfering attention head 8: sa_sdp_64\n",
      "\tTransfering attention head 9: sa_sdp_64\n",
      "\tTransfering attention head 10: sa_sdp_64\n",
      "\tTransfering attention head 11: sa_sdp_64\n",
      "\tTransfering feed-forward layer 0\n",
      "Checking layer 1...\n",
      "\tLoading distace embeddings directly\n",
      "\tTransfering attention head 0: sa_sdp_64\n",
      "\tTransfering attention head 1: sa_sdp_64\n",
      "\tTransfering attention head 2: sa_sdp_64\n",
      "\tTransfering attention head 3: sa_sdp_64\n",
      "\tTransfering attention head 4: sa_sdp_64\n",
      "\tTransfering attention head 5: sa_sdp_64\n",
      "\tTransfering attention head 6: sa_sdp_64\n",
      "\tTransfering attention head 7: sa_sdp_64\n",
      "\tTransfering attention head 8: sa_sdp_64\n",
      "\tTransfering attention head 9: sa_sdp_64\n",
      "\tTransfering attention head 10: sa_sdp_64\n",
      "\tTransfering attention head 11: sa_sdp_64\n",
      "\tTransfering feed-forward layer 0\n",
      "Checking layer 2...\n",
      "\tLoading distace embeddings directly\n",
      "\tTransfering attention head 0: sa_sdp_64\n",
      "\tTransfering attention head 1: sa_sdp_64\n",
      "\tTransfering attention head 2: sa_sdp_64\n",
      "\tTransfering attention head 3: sa_sdp_64\n",
      "\tTransfering attention head 4: sa_sdp_64\n",
      "\tTransfering attention head 5: sa_sdp_64\n",
      "\tTransfering attention head 6: sa_sdp_64\n",
      "\tTransfering attention head 7: sa_sdp_64\n",
      "\tTransfering attention head 8: sa_sdp_64\n",
      "\tTransfering attention head 9: sa_sdp_64\n",
      "\tTransfering attention head 10: sa_sdp_64\n",
      "\tTransfering attention head 11: sa_sdp_64\n",
      "\tTransfering feed-forward layer 0\n",
      "Checking layer 3...\n",
      "\tLoading distace embeddings directly\n",
      "\tTransfering attention head 0: sa_sdp_64\n",
      "\tTransfering attention head 1: sa_sdp_64\n",
      "\tTransfering attention head 2: sa_sdp_64\n",
      "\tTransfering attention head 3: sa_sdp_64\n",
      "\tTransfering attention head 4: sa_sdp_64\n",
      "\tTransfering attention head 5: sa_sdp_64\n",
      "\tTransfering attention head 6: sa_sdp_64\n",
      "\tTransfering attention head 7: sa_sdp_64\n",
      "\tTransfering attention head 8: sa_sdp_64\n",
      "\tTransfering attention head 9: sa_sdp_64\n",
      "\tTransfering attention head 10: sa_sdp_64\n",
      "\tTransfering attention head 11: sa_sdp_64\n",
      "\tTransfering feed-forward layer 0\n",
      "Checking layer 4...\n",
      "\tLoading distace embeddings directly\n",
      "\tTransfering attention head 0: sa_sdp_64\n",
      "\tTransfering attention head 1: sa_sdp_64\n",
      "\tTransfering attention head 2: sa_sdp_64\n",
      "\tTransfering attention head 3: sa_sdp_64\n",
      "\tTransfering attention head 4: sa_sdp_64\n",
      "\tTransfering attention head 5: sa_sdp_64\n",
      "\tTransfering attention head 6: sa_sdp_64\n",
      "\tTransfering attention head 7: sa_sdp_64\n",
      "\tTransfering attention head 8: sa_sdp_64\n",
      "\tTransfering attention head 9: sa_sdp_64\n",
      "\tTransfering attention head 10: sa_sdp_64\n",
      "\tTransfering attention head 11: sa_sdp_64\n",
      "\tTransfering feed-forward layer 0\n",
      "Checking layer 5...\n",
      "\tLoading distace embeddings directly\n",
      "\tTransfering attention head 0: sa_sdp_64\n",
      "\tTransfering attention head 1: sa_sdp_64\n",
      "\tTransfering attention head 2: sa_sdp_64\n",
      "\tTransfering attention head 3: sa_sdp_64\n",
      "\tTransfering attention head 4: sa_sdp_64\n",
      "\tTransfering attention head 5: sa_sdp_64\n",
      "\tTransfering attention head 6: sa_sdp_64\n",
      "\tTransfering attention head 7: sa_sdp_64\n",
      "\tTransfering attention head 8: sa_sdp_64\n",
      "\tTransfering attention head 9: sa_sdp_64\n",
      "\tTransfering attention head 10: sa_sdp_64\n",
      "\tTransfering attention head 11: sa_sdp_64\n",
      "\tTransfering feed-forward layer 0\n",
      "Checking layer 6...\n",
      "\tLoading distace embeddings directly\n",
      "\tTransfering attention head 0: sa_sdp_64\n",
      "\tTransfering attention head 1: sa_sdp_64\n",
      "\tTransfering attention head 2: sa_sdp_64\n",
      "\tTransfering attention head 3: sa_sdp_64\n",
      "\tTransfering attention head 4: sa_sdp_64\n",
      "\tTransfering attention head 5: sa_sdp_64\n",
      "\tTransfering attention head 6: sa_sdp_64\n",
      "\tTransfering attention head 7: sa_sdp_64\n",
      "\tTransfering attention head 8: sa_sdp_64\n",
      "\tTransfering attention head 9: sa_sdp_64\n",
      "\tTransfering attention head 10: sa_sdp_64\n",
      "\tTransfering attention head 11: sa_sdp_64\n",
      "\tTransfering feed-forward layer 0\n",
      "Checking layer 7...\n",
      "\tLoading distace embeddings directly\n",
      "\tTransfering attention head 0: sa_sdp_64\n",
      "\tTransfering attention head 1: sa_sdp_64\n",
      "\tTransfering attention head 2: sa_sdp_64\n",
      "\tTransfering attention head 3: sa_sdp_64\n",
      "\tTransfering attention head 4: sa_sdp_64\n",
      "\tTransfering attention head 5: sa_sdp_64\n",
      "\tTransfering attention head 6: sa_sdp_64\n",
      "\tTransfering attention head 7: sa_sdp_64\n",
      "\tTransfering attention head 8: sa_sdp_64\n",
      "\tTransfering attention head 9: sa_sdp_64\n",
      "\tTransfering attention head 10: sa_sdp_64\n",
      "\tTransfering attention head 11: sa_sdp_64\n",
      "\tTransfering feed-forward layer 0\n",
      "Checking layer 8...\n",
      "\tLoading distace embeddings directly\n",
      "\tTransfering attention head 0: sa_sdp_64\n",
      "\tTransfering attention head 1: sa_sdp_64\n",
      "\tTransfering attention head 2: sa_sdp_64\n",
      "\tTransfering attention head 3: sa_sdp_64\n",
      "\tTransfering attention head 4: sa_sdp_64\n",
      "\tTransfering attention head 5: sa_sdp_64\n",
      "\tTransfering attention head 6: sa_sdp_64\n",
      "\tTransfering attention head 7: sa_sdp_64\n",
      "\tTransfering attention head 8: sa_sdp_64\n",
      "\tTransfering attention head 9: sa_sdp_64\n",
      "\tTransfering attention head 10: sa_sdp_64\n",
      "\tTransfering attention head 11: sa_sdp_64\n",
      "\tTransfering feed-forward layer 0\n",
      "Checking layer 9...\n",
      "\tLoading distace embeddings directly\n",
      "\tTransfering attention head 0: sa_sdp_64\n",
      "\tTransfering attention head 1: sa_sdp_64\n",
      "\tTransfering attention head 2: sa_sdp_64\n",
      "\tTransfering attention head 3: sa_sdp_64\n",
      "\tTransfering attention head 4: sa_sdp_64\n",
      "\tTransfering attention head 5: sa_sdp_64\n",
      "\tTransfering attention head 6: sa_sdp_64\n",
      "\tTransfering attention head 7: sa_sdp_64\n",
      "\tTransfering attention head 8: sa_sdp_64\n",
      "\tTransfering attention head 9: sa_sdp_64\n",
      "\tTransfering attention head 10: sa_sdp_64\n",
      "\tTransfering attention head 11: sa_sdp_64\n",
      "\tTransfering feed-forward layer 0\n",
      "Checking layer 10...\n",
      "\tLoading distace embeddings directly\n",
      "\tTransfering attention head 0: sa_sdp_64\n",
      "\tTransfering attention head 1: sa_sdp_64\n",
      "\tTransfering attention head 2: sa_sdp_64\n",
      "\tTransfering attention head 3: sa_sdp_64\n",
      "\tTransfering attention head 4: sa_sdp_64\n",
      "\tTransfering attention head 5: sa_sdp_64\n",
      "\tTransfering attention head 6: sa_sdp_64\n",
      "\tTransfering attention head 7: sa_sdp_64\n",
      "\tTransfering attention head 8: sa_sdp_64\n",
      "\tTransfering attention head 9: sa_sdp_64\n",
      "\tTransfering attention head 10: sa_sdp_64\n",
      "\tTransfering attention head 11: sa_sdp_64\n",
      "\tTransfering feed-forward layer 0\n",
      "Checking layer 11...\n",
      "\tLoading distace embeddings directly\n",
      "\tTransfering attention head 0: sa_sdp_64\n",
      "\tTransfering attention head 1: sa_sdp_64\n",
      "\tTransfering attention head 2: sa_sdp_64\n",
      "\tTransfering attention head 3: sa_sdp_64\n",
      "\tTransfering attention head 4: sa_sdp_64\n",
      "\tTransfering attention head 5: sa_sdp_64\n",
      "\tTransfering attention head 6: sa_sdp_64\n",
      "\tTransfering attention head 7: sa_sdp_64\n",
      "\tTransfering attention head 8: sa_sdp_64\n",
      "\tTransfering attention head 9: sa_sdp_64\n",
      "\tTransfering attention head 10: sa_sdp_64\n",
      "\tTransfering attention head 11: sa_sdp_64\n",
      "\tTransfering feed-forward layer 0\n",
      "Transfering MLM head\n",
      "\n",
      "Model key: bert.embeddings.position_ids is not transferred (or has 514 same weights)\n",
      "Model key: bert.encoder.layer.0.attention.self.W0 is not transferred (or has 4096 same weights)\n",
      "Model key: bert.encoder.layer.0.attention.self.query.weight is not transferred (or has 49152 same weights)\n",
      "Model key: bert.encoder.layer.0.attention.self.query.bias is not transferred (or has 64 same weights)\n",
      "Model key: bert.encoder.layer.0.attention.self.key.weight is not transferred (or has 49152 same weights)\n",
      "Model key: bert.encoder.layer.0.attention.self.key.bias is not transferred (or has 64 same weights)\n",
      "Model key: bert.encoder.layer.0.attention.self.value.weight is not transferred (or has 49152 same weights)\n",
      "Model key: bert.encoder.layer.0.attention.self.value.bias is not transferred (or has 64 same weights)\n",
      "Model key: bert.encoder.layer.0.attention.output.dense.weight is not transferred (or has 49152 same weights)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight transfer ratio: 0.9989547729492188\n",
      "Namespace(local_rank=-1, output_dir='../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7', steps=500)\n",
      "02/19/2022 16:33:54 - WARNING - roberta_pretraining -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "02/19/2022 16:33:54 - INFO - roberta_pretraining -   Training/evaluation parameters TrainingArguments(output_dir=../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7, overwrite_output_dir=False, do_train=True, do_eval=None, do_predict=False, evaluation_strategy=IntervalStrategy.NO, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, gradient_accumulation_steps=4, eval_accumulation_steps=None, learning_rate=0.0001, weight_decay=0.01, adam_beta1=0.9, adam_beta2=0.98, adam_epsilon=1e-06, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=100500, lr_scheduler_type=SchedulerType.LINEAR, warmup_ratio=0.0, warmup_steps=10000, logging_dir=runs/Feb19_16-33-54_della-i14g3, logging_strategy=IntervalStrategy.STEPS, logging_first_step=False, logging_steps=10, save_strategy=IntervalStrategy.STEPS, save_steps=10, save_total_limit=2, no_cuda=False, seed=0, fp16=False, fp16_opt_level=O1, fp16_backend=auto, fp16_full_eval=False, local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=10, dataloader_num_workers=0, past_index=-1, run_name=../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7, disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, length_column_name=length, report_to=[], ddp_find_unused_parameters=None, dataloader_pin_memory=True, skip_memory_metrics=False, _n_gpu=1, mp_parameters=)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|tokenization_utils_base.py:1647] 2022-02-19 16:33:54,622 >> Didn't find file /scratch/gpfs/stuli/txf_design-space/roberta_tokenizer/added_tokens.json. We won't load it.\n",
      "[INFO|tokenization_utils_base.py:1647] 2022-02-19 16:33:54,622 >> Didn't find file /scratch/gpfs/stuli/txf_design-space/roberta_tokenizer/tokenizer.json. We won't load it.\n",
      "[INFO|tokenization_utils_base.py:1711] 2022-02-19 16:33:54,623 >> loading file /scratch/gpfs/stuli/txf_design-space/roberta_tokenizer/vocab.json\n",
      "[INFO|tokenization_utils_base.py:1711] 2022-02-19 16:33:54,623 >> loading file /scratch/gpfs/stuli/txf_design-space/roberta_tokenizer/merges.txt\n",
      "[INFO|tokenization_utils_base.py:1711] 2022-02-19 16:33:54,623 >> loading file None\n",
      "[INFO|tokenization_utils_base.py:1711] 2022-02-19 16:33:54,624 >> loading file /scratch/gpfs/stuli/txf_design-space/roberta_tokenizer/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:1711] 2022-02-19 16:33:54,624 >> loading file /scratch/gpfs/stuli/txf_design-space/roberta_tokenizer/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:1711] 2022-02-19 16:33:54,624 >> loading file None\n",
      "[INFO|trainer.py:375] 2022-02-19 16:34:01,359 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:488] 2022-02-19 16:34:01,360 >> The following columns in the training set  don't have a corresponding argument in `BertForMaskedLMModular.forward` and have been ignored: special_tokens_mask.\n",
      "[INFO|trainer.py:919] 2022-02-19 16:34:01,360 >> Loading model from ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100000).\n",
      "[INFO|configuration_utils.py:488] 2022-02-19 16:34:01,362 >> loading configuration file ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100000/config.json\n",
      "[INFO|configuration_utils.py:526] 2022-02-19 16:34:01,363 >> Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLMModular\"\n",
      "  ],\n",
      "  \"attention_heads_list\": [\n",
      "    [\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_wma_64\"\n",
      "    ],\n",
      "    [\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\"\n",
      "    ],\n",
      "    [\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\"\n",
      "    ],\n",
      "    [\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\"\n",
      "    ],\n",
      "    [\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\"\n",
      "    ],\n",
      "    [\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\"\n",
      "    ],\n",
      "    [\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\"\n",
      "    ],\n",
      "    [\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\"\n",
      "    ],\n",
      "    [\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\"\n",
      "    ],\n",
      "    [\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\"\n",
      "    ],\n",
      "    [\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\"\n",
      "    ],\n",
      "    [\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\",\n",
      "      \"sa_sdp_64\"\n",
      "    ]\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"conv_kernel_size\": 9,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ff_dim_list\": [\n",
      "    [\n",
      "      3072\n",
      "    ],\n",
      "    [\n",
      "      3072\n",
      "    ],\n",
      "    [\n",
      "      3072\n",
      "    ],\n",
      "    [\n",
      "      3072\n",
      "    ],\n",
      "    [\n",
      "      3072\n",
      "    ],\n",
      "    [\n",
      "      3072\n",
      "    ],\n",
      "    [\n",
      "      3072\n",
      "    ],\n",
      "    [\n",
      "      3072\n",
      "    ],\n",
      "    [\n",
      "      3072\n",
      "    ],\n",
      "    [\n",
      "      3072\n",
      "    ],\n",
      "    [\n",
      "      3072\n",
      "    ],\n",
      "    [\n",
      "      3072\n",
      "    ]\n",
      "  ],\n",
      "  \"from_model_dict_hetero\": true,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"head_ratio\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dim_list\": [\n",
      "    768,\n",
      "    768,\n",
      "    768,\n",
      "    768,\n",
      "    768,\n",
      "    768,\n",
      "    768,\n",
      "    768,\n",
      "    768,\n",
      "    768,\n",
      "    768,\n",
      "    768\n",
      "  ],\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"relative_key\",\n",
      "  \"transformers_version\": \"4.6.0.dev0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:1067] 2022-02-19 16:34:01,364 >> loading weights file ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100000/pytorch_model.bin\n",
      "[INFO|modeling_utils.py:1198] 2022-02-19 16:34:05,022 >> All model checkpoint weights were used when initializing BertForMaskedLMModular.\n",
      "\n",
      "[INFO|modeling_utils.py:1206] 2022-02-19 16:34:05,023 >> All the weights of BertForMaskedLMModular were initialized from the model checkpoint at ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLMModular for predictions without further training.\n",
      "[WARNING|training_args.py:633] 2022-02-19 16:34:05,091 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
      "[WARNING|training_args.py:633] 2022-02-19 16:34:05,095 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
      "[INFO|trainer.py:1011] 2022-02-19 16:34:05,095 >> ***** Running training *****\n",
      "[INFO|trainer.py:1012] 2022-02-19 16:34:05,095 >>   Num examples = 3149357\n",
      "[INFO|trainer.py:1013] 2022-02-19 16:34:05,096 >>   Num Epochs = 3\n",
      "[INFO|trainer.py:1014] 2022-02-19 16:34:05,096 >>   Instantaneous batch size per device = 8\n",
      "[INFO|trainer.py:1015] 2022-02-19 16:34:05,096 >>   Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "[INFO|trainer.py:1016] 2022-02-19 16:34:05,096 >>   Gradient Accumulation steps = 4\n",
      "[INFO|trainer.py:1017] 2022-02-19 16:34:05,096 >>   Total optimization steps = 100500\n",
      "[INFO|trainer.py:1036] 2022-02-19 16:34:05,098 >>   Continuing training from checkpoint, will skip to saved global_step\n",
      "[INFO|trainer.py:1037] 2022-02-19 16:34:05,098 >>   Continuing training from epoch 2\n",
      "[INFO|trainer.py:1038] 2022-02-19 16:34:05,099 >>   Continuing training from global step 100000\n",
      "[INFO|trainer.py:1040] 2022-02-19 16:34:05,099 >>   Will skip the first 2 epochs then the first 6336 batches in the first epoch.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100073' max='100500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100073/100500 03:18 < 19:51, 0.36 it/s, Epoch 2.03/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100010</td>\n",
       "      <td>1.347700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100020</td>\n",
       "      <td>1.318000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100030</td>\n",
       "      <td>1.347900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100040</td>\n",
       "      <td>1.341100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100050</td>\n",
       "      <td>1.329800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100060</td>\n",
       "      <td>1.313100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100070</td>\n",
       "      <td>1.322100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:1667] 2022-02-19 16:36:47,666 >> Saving model checkpoint to ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100010\n",
      "[INFO|configuration_utils.py:329] 2022-02-19 16:36:47,670 >> Configuration saved in ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100010/config.json\n",
      "[INFO|modeling_utils.py:848] 2022-02-19 16:36:48,234 >> Model weights saved in ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100010/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:1907] 2022-02-19 16:36:48,235 >> tokenizer config file saved in ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100010/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:1913] 2022-02-19 16:36:48,235 >> Special tokens file saved in ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100010/special_tokens_map.json\n",
      "[INFO|trainer.py:1734] 2022-02-19 16:36:49,549 >> Deleting older checkpoint [../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-99500] due to args.save_total_limit\n",
      "[INFO|trainer.py:1667] 2022-02-19 16:37:15,587 >> Saving model checkpoint to ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100020\n",
      "[INFO|configuration_utils.py:329] 2022-02-19 16:37:15,588 >> Configuration saved in ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100020/config.json\n",
      "[INFO|modeling_utils.py:848] 2022-02-19 16:37:16,151 >> Model weights saved in ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100020/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:1907] 2022-02-19 16:37:16,152 >> tokenizer config file saved in ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100020/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:1913] 2022-02-19 16:37:16,153 >> Special tokens file saved in ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100020/special_tokens_map.json\n",
      "[INFO|trainer.py:1734] 2022-02-19 16:37:17,425 >> Deleting older checkpoint [../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100000] due to args.save_total_limit\n",
      "[INFO|trainer.py:1667] 2022-02-19 16:37:43,510 >> Saving model checkpoint to ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100030\n",
      "[INFO|configuration_utils.py:329] 2022-02-19 16:37:43,513 >> Configuration saved in ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100030/config.json\n",
      "[INFO|modeling_utils.py:848] 2022-02-19 16:37:44,079 >> Model weights saved in ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100030/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:1907] 2022-02-19 16:37:44,080 >> tokenizer config file saved in ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100030/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:1913] 2022-02-19 16:37:44,081 >> Special tokens file saved in ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100030/special_tokens_map.json\n",
      "[INFO|trainer.py:1734] 2022-02-19 16:37:45,381 >> Deleting older checkpoint [../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100010] due to args.save_total_limit\n",
      "[INFO|trainer.py:1667] 2022-02-19 16:38:11,507 >> Saving model checkpoint to ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100040\n",
      "[INFO|configuration_utils.py:329] 2022-02-19 16:38:11,508 >> Configuration saved in ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100040/config.json\n",
      "[INFO|modeling_utils.py:848] 2022-02-19 16:38:12,074 >> Model weights saved in ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100040/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:1907] 2022-02-19 16:38:12,076 >> tokenizer config file saved in ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100040/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:1913] 2022-02-19 16:38:12,076 >> Special tokens file saved in ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100040/special_tokens_map.json\n",
      "[INFO|trainer.py:1734] 2022-02-19 16:38:13,297 >> Deleting older checkpoint [../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100020] due to args.save_total_limit\n",
      "[INFO|trainer.py:1667] 2022-02-19 16:38:39,370 >> Saving model checkpoint to ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100050\n",
      "[INFO|configuration_utils.py:329] 2022-02-19 16:38:39,372 >> Configuration saved in ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100050/config.json\n",
      "[INFO|modeling_utils.py:848] 2022-02-19 16:38:39,954 >> Model weights saved in ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100050/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:1907] 2022-02-19 16:38:39,957 >> tokenizer config file saved in ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100050/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:1913] 2022-02-19 16:38:39,957 >> Special tokens file saved in ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100050/special_tokens_map.json\n",
      "[INFO|trainer.py:1734] 2022-02-19 16:38:41,289 >> Deleting older checkpoint [../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100030] due to args.save_total_limit\n",
      "[INFO|trainer.py:1667] 2022-02-19 16:39:07,426 >> Saving model checkpoint to ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100060\n",
      "[INFO|configuration_utils.py:329] 2022-02-19 16:39:07,428 >> Configuration saved in ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100060/config.json\n",
      "[INFO|modeling_utils.py:848] 2022-02-19 16:39:07,997 >> Model weights saved in ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100060/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:1907] 2022-02-19 16:39:07,998 >> tokenizer config file saved in ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100060/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:1913] 2022-02-19 16:39:07,998 >> Special tokens file saved in ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100060/special_tokens_map.json\n",
      "[INFO|trainer.py:1734] 2022-02-19 16:39:09,203 >> Deleting older checkpoint [../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100040] due to args.save_total_limit\n",
      "[INFO|trainer.py:1667] 2022-02-19 16:39:35,408 >> Saving model checkpoint to ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100070\n",
      "[INFO|configuration_utils.py:329] 2022-02-19 16:39:35,410 >> Configuration saved in ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100070/config.json\n",
      "[INFO|modeling_utils.py:848] 2022-02-19 16:39:35,962 >> Model weights saved in ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100070/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:1907] 2022-02-19 16:39:35,964 >> tokenizer config file saved in ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100070/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:1913] 2022-02-19 16:39:35,965 >> Special tokens file saved in ../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100070/special_tokens_map.json\n",
      "[INFO|trainer.py:1734] 2022-02-19 16:39:37,212 >> Deleting older checkpoint [../models/8ee1fe926fcd3cb9d1775ce7c4f5f8d7/checkpoint-100050] due to args.save_total_limit\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0087ace9773e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0mpretrain_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/gpfs/stuli/edge_txf/tests/../grow_and_prune/pretrain_model.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m# Pre-train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;31m# Save log history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/gpfs/stuli/edge_txf/tests/../../txf_design-space/flexibert/roberta_pretraining.py\u001b[0m in \u001b[0;36mpretrain\u001b[0;34m(args, model_dict)\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m         \u001b[0mtrain_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Saves the tokenizer too for easy upload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/gpfs/stuli/txf_design-space/transformers/src/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, **kwargs)\u001b[0m\n\u001b[1;32m   1116\u001b[0m                         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1118\u001b[0;31m                     \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1119\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_flos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/gpfs/stuli/txf_design-space/transformers/src/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1514\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1515\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1516\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1518\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/gpfs/stuli/txf_design-space/transformers/src/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   1546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1547\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1548\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1549\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/txf_design-space/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/gpfs/stuli/txf_design-space/transformers/src/transformers/models/bert/modeling_modular_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   2340\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2342\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   2343\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2344\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/txf_design-space/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/gpfs/stuli/txf_design-space/transformers/src/transformers/models/bert/modeling_modular_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1976\u001b[0m         )\n\u001b[1;32m   1977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1978\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1979\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1980\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/txf_design-space/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/gpfs/stuli/txf_design-space/transformers/src/transformers/models/bert/modeling_modular_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1355\u001b[0m                 )\n\u001b[1;32m   1356\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1357\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m   1358\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/txf_design-space/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/gpfs/stuli/txf_design-space/transformers/src/transformers/models/bert/modeling_modular_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    875\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    878\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/txf_design-space/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/gpfs/stuli/txf_design-space/transformers/src/transformers/models/bert/modeling_modular_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m     ):\n\u001b[0;32m--> 777\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/txf_design-space/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/gpfs/stuli/txf_design-space/transformers/src/transformers/models/bert/modeling_modular_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mattention_scores_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mattention_scores_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0mwma_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Test pretrain_model.py\n",
    "PREFIX_CHECKPOINT_DIR = \"checkpoint\"\n",
    "bert_hash = '07aaba14d29455a984e2aef6312a8870'\n",
    "\n",
    "models_dir = '../models/'\n",
    "model_dict_bert_base = json.load(open(os.path.join(models_dir, bert_hash, 'model_dict.json'), 'r'))\n",
    "model_dict = deepcopy(model_dict_bert_base)\n",
    "model_dict['o'][0].append('sa_wma_64')\n",
    "print(model_dict)\n",
    "\n",
    "model_graph = graph_util.model_dict_to_graph(model_dict)\n",
    "model_hash = graph_util.hash_graph(*model_graph)\n",
    "\n",
    "chosen_neighbor_path = os.path.join(models_dir, bert_hash)\n",
    "model_path = os.path.join(models_dir, model_hash)\n",
    "\n",
    "chosen_neighbor_model = BertForMaskedLMModular.from_pretrained(chosen_neighbor_path)\n",
    "\n",
    "# Finding the latest checkpoint for chosen neighbor\n",
    "re_checkpoint = re.compile(r\"^\" + PREFIX_CHECKPOINT_DIR + r\"\\-(\\d+)$\")\n",
    "content = os.listdir(chosen_neighbor_path)\n",
    "checkpoints = [\n",
    "        path\n",
    "        for path in content\n",
    "        if re_checkpoint.search(path) is not None and os.path.isdir(os.path.join(chosen_neighbor_path, path))\n",
    "    ]\n",
    "checkpoint_dir = max(checkpoints, key=lambda x: int(re_checkpoint.search(x).groups()[0]))\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('../txf_design-space/roberta_tokenizer/')\n",
    "config_new = BertConfig(vocab_size = tokenizer.vocab_size)\n",
    "config_new.from_model_dict_hetero(model_dict)\n",
    "\n",
    "# Transfer weights from chosen neighbor to the current model\n",
    "model = BertForMaskedLMModular(config_new, transfer_mode='RP')\n",
    "wt_ratio = model.load_model_from_source(chosen_neighbor_model, debug=True)\n",
    "print(f'Weight transfer ratio: {wt_ratio}')\n",
    "\n",
    "# Setting up checkpoint for the current model\n",
    "if os.path.exists(model_path):\n",
    "    shutil.rmtree(model_path)\n",
    "\n",
    "shutil.copytree(os.path.join(chosen_neighbor_path), os.path.join(model_path))\n",
    "\n",
    "try:\n",
    "    os.remove(os.path.join(model_path, checkpoint_dir, 'optimizer.pt'))\n",
    "    # os.remove(os.path.join(output_dir_new, checkpoint_dir, 'scheduler.pt'))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "model.save_pretrained(os.path.join(model_path, checkpoint_dir))\n",
    "\n",
    "# Save model dictionary\n",
    "json.dump(model_dict, open(os.path.join(models_dir, model_hash, 'model_dict.json'), 'w+'))\n",
    "\n",
    "parser = argparse.ArgumentParser(\n",
    "    description='Input parameters for pretraining',\n",
    "    formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "parser.add_argument('--output_dir',\n",
    "    metavar='',\n",
    "    type=str,\n",
    "    default=model_path,\n",
    "    help='path to save the pretrained model')\n",
    "parser.add_argument('--steps',\n",
    "    metavar='',\n",
    "    type=int,\n",
    "    default=500,\n",
    "    help='number of steps to pre-train beyond latest checkpoint')\n",
    "parser.add_argument('--local_rank',\n",
    "    metavar='',\n",
    "    type=int,\n",
    "    help='rank of the process during distributed training',\n",
    "    default=-1)\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "pretrain_model.main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model dictionary for BERT-Base\n",
    "model_dict_bert_base = {'l': 12, 'o': [['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', \\\n",
    "                                       'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', \\\n",
    "                                       'sa_sdp_64', 'sa_sdp_64'], \\\n",
    "                                      ['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', \\\n",
    "                                       'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', \\\n",
    "                                       'sa_sdp_64', 'sa_sdp_64'], \\\n",
    "                                      ['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', \\\n",
    "                                       'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', \\\n",
    "                                       'sa_sdp_64', 'sa_sdp_64'], \\\n",
    "                                      ['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', \\\n",
    "                                       'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', \\\n",
    "                                       'sa_sdp_64', 'sa_sdp_64'], \\\n",
    "                                      ['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', \\\n",
    "                                       'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', \\\n",
    "                                       'sa_sdp_64', 'sa_sdp_64'], \\\n",
    "                                      ['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', \\\n",
    "                                       'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', \\\n",
    "                                       'sa_sdp_64', 'sa_sdp_64'], \\\n",
    "                                      ['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', \\\n",
    "                                       'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', \\\n",
    "                                       'sa_sdp_64', 'sa_sdp_64'], \\\n",
    "                                      ['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', \\\n",
    "                                       'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', \\\n",
    "                                       'sa_sdp_64', 'sa_sdp_64'], \\\n",
    "                                      ['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', \\\n",
    "                                       'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', \\\n",
    "                                       'sa_sdp_64', 'sa_sdp_64'], \\\n",
    "                                      ['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', \\\n",
    "                                       'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', \\\n",
    "                                       'sa_sdp_64', 'sa_sdp_64'], \\\n",
    "                                      ['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', \\\n",
    "                                       'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', \\\n",
    "                                       'sa_sdp_64', 'sa_sdp_64'], \\\n",
    "                                      ['sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', \\\n",
    "                                       'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', 'sa_sdp_64', \\\n",
    "                                       'sa_sdp_64', 'sa_sdp_64']], 'h': [768, 768, 768, 768, 768, 768, \\\n",
    "                                                                        768, 768, 768, 768, 768, 768], \\\n",
    "                                                                    'f': [[3072], [3072], [3072], \\\n",
    "                                                                        [3072], [3072], [3072], [3072], [3072], \\\n",
    "                                                                        [3072], [3072], [3072], [3072]]}\n",
    "json.dump(model_dict_bert_base, open(os.path.join(models_dir, bert_hash, 'model_dict.json'), 'w+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss curves of different models\n",
    "models_dir = '../models'\n",
    "\n",
    "experiments = ['grow_w_ffnn', 'grow_wo_ffnn']\n",
    "\n",
    "def moving_average(x, w):\n",
    "    return np.convolve(x, np.ones(w), 'same') / w\n",
    "\n",
    "for exp in experiments:\n",
    "    log_histories = {}\n",
    "    fig, ax = plt.subplots()\n",
    "    kernel = 10 if exp == 'grow_wo_ffnn' else 1\n",
    "    for model_hash in os.listdir(os.path.join(models_dir, exp)):\n",
    "        log_history = json.load(open(os.path.join(models_dir, exp, model_hash, 'log_history.json')))\n",
    "        ax.plot([state['step'] for state in log_history[:-1]], \n",
    "                moving_average([state['loss'] for state in log_history[:-1]], kernel),\n",
    "                label=model_hash)\n",
    "    ax.legend()\n",
    "    ax.set_xlim([90000, 107000])\n",
    "    if exp == 'grow_w_ffnn': \n",
    "        ax.set_ylim([1.3, 1.6])\n",
    "    else:\n",
    "        ax.set_ylim([1.31, 1.34])\n",
    "    ax.set_xlabel('Steps')\n",
    "    ax.set_ylabel('Loss')\n",
    "    plt.grid()\n",
    "    ax.set_title(exp)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "txf_design-space [~/.conda/envs/txf_design-space/]",
   "language": "python",
   "name": "conda_txf_design-space"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
